{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdNWQm85a3MvzvqpRwW+yS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshsaud/SparkDataAnalysis/blob/main/SportDataAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OLvyutdUYIj",
        "outputId": "5b0b8d2e-483e-4da0-b412-a8dc3e09aa20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.4)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
        "from pyspark.sql.window import Window\n"
      ],
      "metadata": {
        "id": "-i9yUlP8clR7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"DineshPractice.me\")\n",
        "    .getOrCreate())\n"
      ],
      "metadata": {
        "id": "G-0ytB5zUdLH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([\n",
        "    StructField(\"user_id\", IntegerType(), True),\n",
        "    StructField(\"kit_id\", IntegerType(), True),\n",
        "    StructField(\"login_date\", StringType(), True),\n",
        "    StructField(\"sessions_count\", IntegerType(), True)\n",
        "])"
      ],
      "metadata": {
        "id": "zscER6H0cZsy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (1, 2, \"2016-03-01\", 5),\n",
        "    (1, 2, \"2016-03-02\", 6),\n",
        "    (2, 3, \"2017-06-25\", 1),\n",
        "    (3, 1, \"2016-03-02\", 0),\n",
        "    (3, 4, \"2018-07-03\", 5)\n",
        "]"
      ],
      "metadata": {
        "id": "7BhFOE0Edfzn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_df = spark.createDataFrame(data=data,schema=schema)\n",
        "\n",
        "input_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0VYU6aUdnSR",
        "outputId": "ec593fc4-dbf9-47cd-eed8-a0596d9bcb18"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+----------+--------------+\n",
            "|user_id|kit_id|login_date|sessions_count|\n",
            "+-------+------+----------+--------------+\n",
            "|      1|     2|2016-03-01|             5|\n",
            "|      1|     2|2016-03-02|             6|\n",
            "|      2|     3|2017-06-25|             1|\n",
            "|      3|     1|2016-03-02|             0|\n",
            "|      3|     4|2018-07-03|             5|\n",
            "+-------+------+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GroupedDF = input_df.groupBy(\"user_id\").agg(\n",
        "    f.min(\"login_date\").alias(\"first_login\"))\n",
        "\n",
        "GroupedDF.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSfAHRXteDIJ",
        "outputId": "eb2b73cd-5b3e-4882-ae66-e770ca384b85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|user_id|first_login|\n",
            "+-------+-----------+\n",
            "|      1| 2016-03-01|\n",
            "|      2| 2017-06-25|\n",
            "|      3| 2016-03-02|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "windowSpec = Window.partitionBy(\"user_id\").orderBy(\"login_date\")\n",
        "\n",
        "\n",
        "rankDf = input_df.withColumn(\"rank\", f.rank().over(windowSpec))\n",
        "\n",
        "rankDf.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9l9bojneVdp",
        "outputId": "ee52a0a1-6410-492d-b1b4-31b0b2c9cdc1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+----------+--------------+----+\n",
            "|user_id|kit_id|login_date|sessions_count|rank|\n",
            "+-------+------+----------+--------------+----+\n",
            "|      1|     2|2016-03-01|             5|   1|\n",
            "|      1|     2|2016-03-02|             6|   2|\n",
            "|      2|     3|2017-06-25|             1|   1|\n",
            "|      3|     1|2016-03-02|             0|   1|\n",
            "|      3|     4|2018-07-03|             5|   2|\n",
            "+-------+------+----------+--------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "windowSpec = Window.partitionBy(\"user_id\").orderBy(\"login_date\")\n",
        "\n",
        "runningDf = input_df.withColumn(\n",
        "    \"Total_Game_session\", f.sum(\"sessions_count\").over(windowSpec)\n",
        "    )\n",
        "\n",
        "runningDf..show()"
      ],
      "metadata": {
        "id": "UmzYFZ-sgseB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a51a7922-6826-483e-8de1-979793f9d8fd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|user_id|\n",
            "+-------+\n",
            "|      1|\n",
            "|      1|\n",
            "|      2|\n",
            "|      3|\n",
            "|      3|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "requiredDf = input_df.withColumn(\n",
        "    \"first_login\", f.min(\"login_date\").over( Window.partitionBy(\"user_id\"))\n",
        "    ).withColumn(\n",
        "        \"lead_data\", f.lead(\"login_date\").over( Window.partitionBy(\"user_id\").orderBy(\"login_date\"))\n",
        "    ).filter(f.datediff(\"lead_data\",\"first_login\") == 1)\n",
        "\n",
        "\n",
        "requiredDf.select(\"user_id\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9GUSxZht6t4",
        "outputId": "1d5553e6-2a11-42f5-ecfb-6d368aae8dff"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|user_id|\n",
            "+-------+\n",
            "|      1|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PySpark Code Explanation\n",
        "\n",
        "This PySpark code snippet performs operations on a DataFrame named `input_df` to identify user login patterns, specifically targeting users who logged in consecutively for two days starting from their first login. The operations include adding new columns and filtering the data based on specific conditions.\n",
        "\n",
        "### Detailed Steps\n",
        "\n",
        "1. **Window Specification**:\n",
        "   - `Window.partitionBy(\"user_id\")`: This part of the code defines a window specification that partitions data by `user_id`. This means operations that follow (like calculating the minimum login date) are performed within each user's data.\n",
        "\n",
        "2. **Add `first_login` Column**:\n",
        "   - `.withColumn(\"first_login\", f.min(\"login_date\").over(Window.partitionBy(\"user_id\")))`: This line adds a new column called `first_login` to the DataFrame. For each user, it calculates the minimum (or first) login date. This calculation is done within the defined window (by user).\n",
        "\n",
        "3. **Add `lead_data` Column**:\n",
        "   - `.withColumn(\"lead_data\", f.lead(\"login_date\").over(Window.partitionBy(\"user_id\").orderBy(\"login_date\")))`: This line adds another column named `lead_data`. It uses the `lead` function to get the login date of the next row within each user's group of data. The data is ordered by `login_date` within each user partition to ensure the correct sequence.\n",
        "\n",
        "4. **Filter Data**:\n",
        "   - `.filter(f.datediff(\"lead_data\",\"first_login\") == 1)`: This filtering step narrows down the DataFrame to rows where the difference between `lead_data` (the following day's login date) and `first_login` is exactly one day. This identifies users who logged in consecutively for at least two days starting from their first login.\n",
        "\n",
        "5. **Order and Display Data**:\n",
        "   - `.orderBy(\"user_id\", \"login_date\")`: Orders the resulting DataFrame by `user_id` and `login_date` to organize the data.\n",
        "   - `.show()`: Displays the DataFrame in a tabular format.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "The resulting DataFrame, `requiredDf`, will show the `user_id`, `login_date`, `first_login`, and `lead_data` for each user who logged in consecutively for the first two days after their first recorded login. This can be useful for analyzing user engagement patterns over time.\n"
      ],
      "metadata": {
        "id": "3HmopQws5OlR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BJWx3s573h-Q"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}